{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600850488512",
   "display_name": "Python 3.7.9 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import Python libraries for analyzing photos of space rocks\n",
    "\n",
    "Now that we have all of the libraries downloaded, we can begin importing them into Jupyter Notebook file. We'll begin by opening or creating a Jupyter Notebook file.\n",
    "\n",
    "Next, we import Matplotlib to help us plot our data:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "Then, we import Numpy, a library we'lll use to process large numerical matrixes (images):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "source": [
    "Import PyTorch to train and process deep learning and AI models:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "source": [
    "Import torchvision (part of pyTorch) to process images and manipulate them (crop, resize):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "source": [
    "Import Python Imagin Library (PIL) to visualize images:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "source": [
    "Finally, we add two libraries that ensure that the plots are shown inline and in high resolution:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "source": [
    "# Import and clean data about photos of space rocks\n",
    "\n",
    "Now that we know about cleaning and separating the data, we can actually apply these principles to our rock classification project.\n",
    "\n",
    "Let's start by dowloading all the data we have about rock images. Then, we'll put it in the same folder as you Jupyter Notebook file. Go to [this Azure Blob storage](https://nasadata.blob.core.windows.net/nasarocks/Data.zip) and download the *Data.zip* folder. Unzop it and put it in the same folder as your Jupyter Notebook file.\n",
    "\n",
    "Because our photos of rocks come in different sizes (small, medium, and large), we crop the imgaes so that they are the same size(22 x 224 pixels). We resize the images because computers expcet images to be same size. If images vary in size, they're not as easy for the computer to process.\n",
    "\n",
    "We resize the images in the first part of the code. At the bottom of the code, you can see that we separate the data into a training variable and a testing variable.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Basalt', 'Highland']\n"
    }
   ],
   "source": [
    "# Tells the machine what folder contains the image data.\n",
    "data_dir = './data'\n",
    "\n",
    "# Function to read the data; crop and resize the images; and then split it into test an train chunks.\n",
    "\n",
    "def load_split_train_test(datadir, valid_size = .2):\n",
    "# This line of code transforms the images.\n",
    "    train_transforms = transforms.Compose([\n",
    "                                        transforms.RandomResizedCrop(224),\n",
    "                                        transforms.Resize(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "                                        transforms.RandomResizedCrop(224),\n",
    "                                        transforms.Resize(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        ])\n",
    "                                        \n",
    "    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir, transform=test_transforms)\n",
    "\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "    testloader = DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# We're using 20% of data for testing.\n",
    "\n",
    "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "source": [
    "# How a computer reads a photo as an image file\n",
    "\n",
    "Now that we have our data cleaned and separated, you migh twonder how to computer reads these images. As somewhat of a spoiler, computer cn't read images the same way you or I see images.\n",
    "\n",
    "If you know something about computers, you know that computers read things in binary: 1s and 0s. So, how can a computer read a complex image as only 1s and 0s? If you break down an image for enough, it too, is just a combination of 1s and 0s.\n",
    "\n",
    "An image will look like the following example after a computer transforms them into numbers.\n",
    "\n",
    "The image is broken down into pixels, and each pixel has a specific color that is identified by a code. After a computer breaks down an image into these codes, it can read and decipher the image."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Display photos of space rocks in Jupyter Notebook\n",
    "\n",
    "Now that we've loaded the images into the computer, let's look at a few of them. We'll give them labels that indicate what type of rock the photos contain.\n",
    "\n",
    "The following code block reads images and then assigns each image with a correspondng rock type. The code looks long,\n",
    "but that's because it needs to match each rock image with the type of rock it is, based on the folder it is in."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the new image into numbers and resize it.\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                    ])\n",
    "\n",
    "# A function to randomly select a set of images\n",
    "\n",
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "    classed = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels"
   ]
  },
  {
   "source": [
    "The following code actually shows you some images that you loaded into the program:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'figzie'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d007920022e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_random_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mto_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigzie\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[1;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[0;32m    675\u001b[0m                                         \u001b[0mframeon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m                                         \u001b[0mFigureClass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFigureClass\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m                                         **kwargs)\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfigLabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;34m\"\"\"Create a new figure manager instance.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_figure_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[1;34m(cls, num, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3491\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3492\u001b[0m         \u001b[0mfig_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureClass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3493\u001b[1;33m         \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3494\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'figzie'"
     ]
    }
   ],
   "source": [
    "# How many images do you want to see? It's set to 5, but you can change the number\n",
    "\n",
    "images, labels = get_random_images(5)\n",
    "to_pil = transforms.ToPILImage()\n",
    "fig =plt.figure(figsize=(20, 20))\n",
    "classes = trainloader.dataset.classes\n",
    "\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    sub = fig.add_subplit(1, len(images), ii+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.show()"
   ]
  }
 ]
}